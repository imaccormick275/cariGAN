{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to GANs\n",
    "\n",
    "Before looking at cycleGANs in depth, we will have to first understand GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:\n",
    "\n",
    "* 3minute introduction: https://www.youtube.com/watch?v=-Upj_VhjTBs\n",
    "\n",
    "### Introduction:\n",
    "\n",
    "Developed in 2014 by Ian Goodfellow to tackle some of the problems with similar Neural Networks. For instance GANs solve the problem that autoencoders have very high computational cost.\n",
    "\n",
    "* Unsupervised learning method\n",
    "* Adversarial: two (or more) competing networks\n",
    "* Capture variations within a dataSet\n",
    "* Require no human supervision\n",
    "\n",
    "### Example:\n",
    "\n",
    "You have a painting and a master forger who wants to create a duplicate painting. The forger does this by understanding how the original artist produced the original artwork. Meanwhile there is an investigator trying to detect the forgery. If the forgery is detected, the master forger is told, and perhaps is also told about what gave the game away. The forger then tries again at creating the perfect forgery. This process is repeated until the forgery gets past the detective.\n",
    "\n",
    "<img src=\"notebook_images/GAN_architecture_simple.png\">\n",
    "\n",
    "* The forger is the generator network (which learns the distribution of classes)\n",
    "* The investigator is the discriminator network (which learns the boundary between thoses classes - the formal shap of the dataSet)\n",
    "\n",
    "<img src=\"notebook_images/GAN_architecture.png\">\n",
    "\n",
    "* R: The original, genuine data set\n",
    "* I: The random noise that goes into the generator as a source of entropy\n",
    "* G: The generator which tries to copy/mimic the original data set\n",
    "* D: The discriminator which tries to tell apart G’s output from R\n",
    "* The actual ‘training’ loop is where we teach G to trick D and D to beware G.\n",
    "* Our cost functions help us determine how G is to trick D and how D is to detect G.\n",
    "\n",
    "\n",
    "### Generative vs Discriminative Models In Depth:\n",
    "\n",
    "##### Generative Model:\n",
    "\n",
    "Aim is to model how data is generated. \"Generative\" since sampling can generate syntheic data points.\n",
    "\n",
    "$ P(X,Y) = P(X|Y) \\cdot P(Y)$\n",
    "\n",
    "<img src=\"notebook_images/generative_model.png\">\n",
    "\n",
    "Examples of generative models:\n",
    "* Guassians, Naive Bayes\n",
    "* Mixture of Guassians, Hidden Markov Models\n",
    "* Sigmoidal belief netowrks, bayesian networks, markov random fields\n",
    "\n",
    "Pros:\n",
    "* We have the knowledge about the data distribution\n",
    "\n",
    "Cons:\n",
    "* Very expensive to get (a lot of parameters)\n",
    "* Need lots of data\n",
    "\n",
    "##### Discriminative Model:\n",
    "\n",
    "* Aim at learning $ P(Y|X) $ using probablistic approacehs (e.g. logistic regression)\n",
    "* Directly estimate posterior probabilities\n",
    "* No attempt to model underlying probability distributions\n",
    "* Focus computational resources on given task - better performance\n",
    "\n",
    "$ P(Y|X) $\n",
    "\n",
    "<img src=\"notebook_images/discriminative_model.png\">\n",
    "\n",
    "Examples of Discriminative Methods:\n",
    "* Logistic Regression, SVMs\n",
    "* Traditional Neural Networks, K Nearest Neighbours\n",
    "* Conditional Random Feilds (CRF)\n",
    "\n",
    "Pros:\n",
    "* Easy to model\n",
    "\n",
    "Cons:\n",
    "* Good at classifying but not to generate data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GAN in TensorFlow:\n",
    "\n",
    "We will go through a really simple example GAN tutuorial to make sure they are well understood\n",
    "\n",
    "* https://www.youtube.com/watch?v=yz6dNf7X7SA\n",
    "\n",
    "We are going to generate brand new Pokemon! More than the original 150 pokemon. We will give the network images of existing pokemon, and the network will output new pokemon. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More on GANs:\n",
    "\n",
    "If you're interested in learning more about GANs take a look at the following:\n",
    "\n",
    "* Deep Convolutional GANs (DCGANs)\n",
    "* Conditional GANs (CGANs)\n",
    "* Wasserstein GANs (WGANs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cariGeoGAN]",
   "language": "python",
   "name": "conda-env-cariGeoGAN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
