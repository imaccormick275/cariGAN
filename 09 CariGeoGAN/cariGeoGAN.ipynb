{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cariGeoGAN\n",
    "\n",
    "See below my implementation of cariGeoGAN. Again, the dataset used to train this network and generate my results is not publically avaliable. You will have to request access to the dataset: https://cs.nju.edu.cn/rl/WebCaricature.htm\n",
    "\n",
    "If you have access to the dataset, or similar you will need to save the faces/caricature coordinates in the subdirectories faces2car/coords_A, faces2car/coords_B and the faces/caricature image datasets in the subdirectories faces2car/images_A, faces2car/images_B\n",
    "\n",
    "<b>Training details:</b> We use the same training strategy to CycleGAN [Zhu et al. 2017a]. For all the experiments, we set $\\lambda_{cyc} = 10 $  and $\\lambda_{cha} = 1$ empirically and use the Adam solver [Kingma and Ba 2014] with a batch size of 1. All networks are trained from scratch with an initial learning rate of 0.0002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imread as _imread\n",
    "from matplotlib.pyplot import imsave as _imwrite\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import PiecewiseAffineTransform, warp\n",
    "from skimage import data\n",
    "from scipy.interpolate import Rbf\n",
    "import cv2\n",
    "#import dlib\n",
    "\n",
    "class PointsRBF:\n",
    "    def __init__(self, src, dst):\n",
    "        xsrc = src[:,0]\n",
    "        ysrc = src[:,1]\n",
    "        xdst = dst[:,0]\n",
    "        ydst = dst[:,1]\n",
    "        self.rbf_x = Rbf( xsrc, ysrc, xdst)\n",
    "        self.rbf_y = Rbf( xsrc, ysrc, ydst)\n",
    "\n",
    "    def __call__(self, xy):\n",
    "        x = xy[:,0]\n",
    "        y = xy[:,1]\n",
    "        xdst = self.rbf_x(x,y)\n",
    "        ydst = self.rbf_y(x,y)\n",
    "        return np.transpose( [xdst,ydst] )\n",
    "\n",
    "def warpRBF(image, src, dst):\n",
    "    prbf = PointsRBF( dst, src)\n",
    "    warped = warp(image, prbf)\n",
    "    warped = 255*warped                         # 0..1 => 0..255\n",
    "    warped = warped.astype(np.uint8)            # convert from float64 to uint8\n",
    "    return warped\n",
    "\n",
    "\n",
    "def add_boundary_coords(coords):\n",
    "    '''    \n",
    "    takes coordinates set with shape (1, 2) and adds points at the boundary of the image\n",
    "    '''\n",
    "    \n",
    "    # add bounary points\n",
    "    coords = np.append(coords, np.array([0, 0]).reshape(1,-1), axis=0)\n",
    "    coords = np.append(coords, np.array([256, 0]).reshape(1,-1), axis=0)\n",
    "    coords = np.append(coords, np.array([0, 256]).reshape(1,-1), axis=0)\n",
    "    coords = np.append(coords, np.array([256, 256]).reshape(1,-1), axis=0)\n",
    "    \n",
    "    return coords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some codes from https://github.com/Newmu/dcgan_code\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "import math\n",
    "import pprint\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import copy\n",
    "from skimage import transform as skimage_transform\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "get_stddev = lambda x, k_h, k_w: 1/math.sqrt(k_w*k_h*x.get_shape()[-1])\n",
    "\n",
    "# -----------------------------\n",
    "# new added functions for cyclegan\n",
    "class ImagePool(object):\n",
    "    def __init__(self, maxsize=50):\n",
    "        self.maxsize = maxsize\n",
    "        self.num_img = 0\n",
    "        self.images = []\n",
    "\n",
    "    def __call__(self, image):\n",
    "        if self.maxsize <= 0:\n",
    "            return image\n",
    "        if self.num_img < self.maxsize:\n",
    "            self.images.append(image)\n",
    "            self.num_img += 1\n",
    "            return image\n",
    "        if np.random.rand() > 0.5:\n",
    "            idx = int(np.random.rand()*self.maxsize)\n",
    "            tmp1 = copy.copy(self.images[idx])[0]\n",
    "            self.images[idx][0] = image[0]\n",
    "            idx = int(np.random.rand()*self.maxsize)\n",
    "            tmp2 = copy.copy(self.images[idx])[1]\n",
    "            self.images[idx][1] = image[1]\n",
    "            return [tmp1, tmp2]\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "def load_test_data(image_path, fine_size=256):\n",
    "    img = imread(image_path)\n",
    "    img = skimage_transform.resize(img, (fine_size, fine_size))\n",
    "    img = img/127.5 - 1\n",
    "    return img\n",
    "\n",
    "def load_train_data(image_path, load_size=286, fine_size=256, is_testing=False):\n",
    "    img_A = imread(image_path[0])\n",
    "    img_B = imread(image_path[1])\n",
    "    if not is_testing:\n",
    "        img_A = skimage_transform.resize(img_A, (load_size, load_size))\n",
    "        img_B = skimage_transform.resize(img_B, (load_size, load_size))\n",
    "\n",
    "        h1 = int(np.ceil(np.random.uniform(1e-2, load_size-fine_size)))\n",
    "        w1 = int(np.ceil(np.random.uniform(1e-2, load_size-fine_size)))\n",
    "        img_A = img_A[h1:h1+fine_size, w1:w1+fine_size]\n",
    "        img_B = img_B[h1:h1+fine_size, w1:w1+fine_size]\n",
    "\n",
    "        if np.random.random() > 0.5:\n",
    "            img_A = np.fliplr(img_A)\n",
    "            img_B = np.fliplr(img_B)\n",
    "    else:\n",
    "        img_A = skimage_transform.resize(img_A, (fine_size, fine_size))\n",
    "        img_B = skimage_transform.resize(img_B, (fine_size, fine_size))\n",
    "\n",
    "    img_A = img_A/127.5 - 1.\n",
    "    img_B = img_B/127.5 - 1.\n",
    "\n",
    "    img_AB = np.concatenate((img_A, img_B), axis=2)\n",
    "    # img_AB shape: (fine_size, fine_size, input_c_dim + output_c_dim)\n",
    "    return img_AB\n",
    "\n",
    "# -----------------------------\n",
    "\n",
    "def get_image(image_path, image_size, is_crop=True, resize_w=64, is_grayscale = False):\n",
    "    return transform(imread(image_path, is_grayscale), image_size, is_crop, resize_w)\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(inverse_transform(images), size, image_path)\n",
    "\n",
    "\n",
    "\n",
    "def imread(path, is_grayscale = False):\n",
    "    if (is_grayscale):\n",
    "        image = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        return gray\n",
    "    else:\n",
    "        image = cv2.imread(path)\n",
    "        return image\n",
    "\n",
    "def merge_images(images, size):\n",
    "    return inverse_transform(images)\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "\n",
    "    return img\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return _imwrite(path, merge(images, size))\n",
    "\n",
    "def center_crop(x, crop_h, crop_w,\n",
    "                resize_h=64, resize_w=64):\n",
    "  if crop_w is None:\n",
    "    crop_w = crop_h\n",
    "  h, w = x.shape[:2]\n",
    "  j = int(round((h - crop_h)/2.))\n",
    "  i = int(round((w - crop_w)/2.))\n",
    "  return skimage_transform.resize(\n",
    "      x[j:j+crop_h, i:i+crop_w], (resize_h, resize_w))\n",
    "\n",
    "def transform(image, npx=64, is_crop=True, resize_w=64):\n",
    "    # npx : # of pixels width/height of image\n",
    "    if is_crop:\n",
    "        cropped_image = center_crop(image, npx, resize_w=resize_w)\n",
    "    else:\n",
    "        cropped_image = image\n",
    "    return np.array(cropped_image)/127.5 - 1.\n",
    "\n",
    "def inverse_transform(images):\n",
    "    return (images+1.)/2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new added functions for cyclegan\n",
    "class ImagePool(object):\n",
    "    def __init__(self, maxsize=50):\n",
    "        self.maxsize = maxsize\n",
    "        self.num_img = 0\n",
    "        self.images = []\n",
    "\n",
    "    def __call__(self, image):\n",
    "        if self.maxsize <= 0:\n",
    "            return image\n",
    "        if self.num_img < self.maxsize:\n",
    "            self.images.append(image)\n",
    "            self.num_img += 1\n",
    "            return image\n",
    "        if np.random.rand() > 0.5:\n",
    "            idx = int(np.random.rand()*self.maxsize)\n",
    "            tmp1 = copy.copy(self.images[idx])[0]\n",
    "            self.images[idx][0] = image[0]\n",
    "            idx = int(np.random.rand()*self.maxsize)\n",
    "            tmp2 = copy.copy(self.images[idx])[1]\n",
    "            self.images[idx][1] = image[1]\n",
    "            return [tmp1, tmp2]\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ops.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "# from utils import *\n",
    "\n",
    "##### New Helper Functions\n",
    "\n",
    "# weight and bais wrappers\n",
    "def weight_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a weight variable with appropriate initialization\n",
    "    :param name: weight name\n",
    "    :param shape: weight shape\n",
    "    :return: initialized weight variable\n",
    "    \"\"\"\n",
    "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "    return tf.get_variable('W_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           shape=shape,\n",
    "                           initializer=initer)\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a bias variable with appropriate initialization\n",
    "    :param name: bias variable name\n",
    "    :param shape: bias variable shape\n",
    "    :return: initialized bias variable\n",
    "    \"\"\"\n",
    "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
    "    return tf.get_variable('b_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           initializer=initial)\n",
    " \n",
    "\n",
    "def fc_layer(x, num_units, name, use_relu=True):\n",
    "    \"\"\"\n",
    "    Create a fully-connected layer\n",
    "    :param x: input from previous layer\n",
    "    :param num_units: number of hidden units in the fully-connected layer\n",
    "    :param name: layer name\n",
    "    :param use_relu: boolean to add ReLU non-linearity (or not)\n",
    "    :return: The output array\n",
    "    \"\"\"\n",
    "    in_dim = x.get_shape()[1]\n",
    "    W = weight_variable(name, shape=[in_dim, num_units])\n",
    "    b = bias_variable(name, [num_units])\n",
    "    layer = tf.matmul(x, W)\n",
    "    layer += b\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### module.py\n",
    "\n",
    "https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/ch04.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "# from ops import *\n",
    "# from utils import *\n",
    "\n",
    "# discriminator network\n",
    "def discriminator(pca_vector, options, reuse=False, name=\"discriminator\"):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "        # image is 256 x 256 x input_c_dim\n",
    "        if reuse:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        else:\n",
    "            assert tf.get_variable_scope().reuse is False\n",
    "            \n",
    "        output_dimension = pca_vector.shape[1]\n",
    "\n",
    "        h0 = fc_layer(pca_vector, 128, name='d_h0', use_relu=True)\n",
    "        # h0 is (128 x 128 x self.df_dim)\n",
    "        h1 = fc_layer(h0, 128, name='d_h1', use_relu=True)\n",
    "        # h1 is (64 x 64 x self.df_dim*2)\n",
    "        h2 = fc_layer(h1, 128, name='d_h2', use_relu=True)\n",
    "        # h2 is (32x 32 x self.df_dim*4)\n",
    "        h3 = fc_layer(h2, 128, name='d_h3', use_relu=True)\n",
    "        # h3 is (32 x 32 x self.df_dim*8)\n",
    "        h4 = fc_layer(h3, output_dimension, name='d_h4', use_relu=True)\n",
    "        # h4 is (32 x 32 x 1)\n",
    "        return h4\n",
    "\n",
    "# generator network without residual block\n",
    "def generator(pca_vector, options, reuse=False, name=\"generator\"):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "        # pca_vector is ((k=32 < m=number of coordinates x 2) x input_c_dim)\n",
    "        if reuse:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        else:\n",
    "            assert tf.get_variable_scope().reuse is False\n",
    "            \n",
    "        output_dimension = pca_vector.shape[1]\n",
    "\n",
    "        # pca_vector is ((k=32 < m=number of coordinates x 2) x input_c_dim)\n",
    "        e1 = fc_layer(pca_vector, 64, name='g_e1', use_relu=True)\n",
    "        # e1 is (128 x 128 x self.gf_dim) 1048576\n",
    "        e2 = fc_layer(e1, 128, name='g_e2', use_relu=True)\n",
    "        # e2 is (64 x 64 x self.gf_dim*2) 524288\n",
    "        e3 = fc_layer(e2, 256, name='g_e3', use_relu=True)\n",
    "        # e3 is (32 x 32 x self.gf_dim*4) 262144\n",
    "        e4 = fc_layer(e3, 512, name='g_e4', use_relu=True)\n",
    "        # e4 is (16 x 16 x self.gf_dim*8) 131072\n",
    "        e5 = fc_layer(e4, 256, name='g_e5', use_relu=True)\n",
    "        # e5 is (8 x 8 x self.gf_dim*8) 32768\n",
    "        e6 = fc_layer(e5, 128, name='g_e6', use_relu=True)\n",
    "        # e6 is (4 x 4 x self.gf_dim*8) 8192\n",
    "        e7 = fc_layer(e6, 64, name='g_e7', use_relu=True)\n",
    "        # e7 is (2 x 2 x self.gf_dim*8) 2048\n",
    "        e8 = fc_layer(e7, output_dimension, name='g_e8', use_relu=False)\n",
    "        # e8 is (1 x 1 x self.gf_dim*8) 512\n",
    "\n",
    "        return e8\n",
    "\n",
    "    \n",
    "# loss function\n",
    "def abs_criterion(in_, target):\n",
    "    return tf.reduce_mean(tf.abs(in_ - target))\n",
    "\n",
    "## loss function\n",
    "def mae_criterion(in_, target):\n",
    "    return tf.reduce_mean((in_-target)**2)\n",
    "\n",
    "## loss function\n",
    "def sce_criterion(logits, labels):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "\n",
    "\n",
    "## loss function\n",
    "def cosine_difference(real_X, real_X_mean, fake_Y, real_Y_mean):\n",
    "\n",
    "    # real_y minus mean of real_Y for all y in Y\n",
    "    A = real_X - real_X_mean\n",
    "\n",
    "    # fake_x minus mean of X for all y in Y\n",
    "    B = fake_Y - real_Y_mean\n",
    "    \n",
    "    normalize_A = tf.nn.l2_normalize(A,1)        \n",
    "    normalize_B = tf.nn.l2_normalize(B,1)\n",
    "    \n",
    "    difference_matrix = 1 - tf.matmul(normalize_A, normalize_B, transpose_b=True)\n",
    "\n",
    "    difference_matrix = tf.diag_part(difference_matrix)\n",
    "    \n",
    "    difference = tf.reduce_sum(difference_matrix)\n",
    "    \n",
    "    return difference\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "# cyclegan class created with build_model, train, save, load, sample_model, new and test methods\n",
    "class cariGeoGAN(object):\n",
    "    def __init__(self, sess, args):\n",
    "        # initialise tensorflow session\n",
    "        self.sess = sess\n",
    "        \n",
    "        # batch size\n",
    "        self.batch_size = args.batch_size\n",
    "        \n",
    "        # data, test, train splits\n",
    "        df_A = pd.read_csv('coords_A.csv', index_col=0)\n",
    "        df_B = pd.read_csv('coords_B.csv', index_col=0)\n",
    "        self.df_A_train, self.df_A_test = train_test_split(df_A, test_size=100, random_state=0)\n",
    "        self.df_B_train, self.df_B_test = train_test_split(df_B, test_size=100, random_state=0)\n",
    "        \n",
    "        \n",
    "        # number of principle components \n",
    "        self.num_components = args.pca_components\n",
    "        \n",
    "        # standard scaler and pca\n",
    "        self.sc_A = StandardScaler()\n",
    "        self.sc_B = StandardScaler()\n",
    "        self.pca_A = PCA(n_components=self.num_components)\n",
    "        self.pca_B = PCA(n_components=self.num_components)\n",
    "        \n",
    "        # create pca data frames, feature scaling,  principle component analysis\n",
    "        self.df_pca_A_train = pd.DataFrame(self.pca_A.fit_transform(self.sc_A.fit_transform(self.df_A_train)), \n",
    "                                           list(self.df_A_train.index))\n",
    "        self.df_pca_B_train = pd.DataFrame(self.pca_B.fit_transform(self.sc_B.fit_transform(self.df_B_train)), \n",
    "                                           list(self.df_B_train.index))\n",
    "\n",
    "        self.df_pca_A_test = pd.DataFrame(self.pca_A.transform(self.sc_A.transform(self.df_A_test)), \n",
    "                                          list(self.df_A_test.index))\n",
    "        self.df_pca_B_test = pd.DataFrame(self.pca_B.transform(self.sc_B.transform(self.df_B_test)), \n",
    "                                          list(self.df_B_test.index))\n",
    "        \n",
    "\n",
    "        \n",
    "        # lambda1 and lambda2 balance the cycle consistancy loss and characteristic (respetively)\n",
    "        self.L1_lambda = args.L1_lambda\n",
    "        self.L2_lambda = args.L2_lambda\n",
    "        \n",
    "        # directory of dataset\n",
    "        self.dataset_dir = args.dataset_dir\n",
    "        \n",
    "        # discriminator and generator networks\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "\n",
    "        # choice of cost function for advasarial loss\n",
    "        if args.use_lsgan:\n",
    "            self.criterionGAN = mae_criterion\n",
    "        else:\n",
    "            self.criterionGAN = sce_criterion\n",
    "\n",
    "        # options for various functions throughout the class\n",
    "        OPTIONS = namedtuple('OPTIONS', 'batch_size image_size \\\n",
    "                              gf_dim df_dim is_training')\n",
    "        self.options = OPTIONS._make((args.batch_size, args.pca_components,\n",
    "                                      args.ngf, args.ndf,\n",
    "                                      args.phase == 'train'))\n",
    "        \n",
    "        # when an instance of class cycleGAN is created, build model is automatically called\n",
    "        self._build_model()\n",
    "        \n",
    "        # saver\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "\n",
    "    def _build_model(self):\n",
    "        \n",
    "        #### INPUTS TO NETWORKS\n",
    "        # placeholder for real data, each dataSet represents one of two ends of the cycle e.g. faces vs cariCatures\n",
    "        self.real_pca_A = tf.placeholder(tf.float32,\n",
    "                                     [None, self.num_components],\n",
    "                                     name='real_A')\n",
    "        self.real_pca_B = tf.placeholder(tf.float32,\n",
    "                                    [None, self.num_components],\n",
    "                                    name='real_B')\n",
    "        self.real_pca_mean_A = tf.placeholder(tf.float32,\n",
    "                                     [None, self.num_components],\n",
    "                                     name='real_A')\n",
    "        self.real_pca_mean_B = tf.placeholder(tf.float32,\n",
    "                                    [None, self.num_components],\n",
    "                                    name='real_B')\n",
    "        \n",
    "        #### GENERATOR NETWORKS\n",
    "        # create two generators: inputA->outputB and inputB->outputA (generator cycle)\n",
    "        # generate fakeB from realA (G)\n",
    "        # generate reconstructedA (comparable to realA) from fakeB (F)\n",
    "        # generate fakeA from realB (F)\n",
    "        # generate reconstructedB (comparable to realB) from fakeA (G)\n",
    "        self.fake_pca_B = self.generator(self.real_pca_A, self.options, False, name=\"generatorA2B\")\n",
    "        self.fake_pca_A_ = self.generator(self.fake_pca_B, self.options, False, name=\"generatorB2A\")\n",
    "        self.fake_pca_A = self.generator(self.real_pca_B, self.options, True, name=\"generatorB2A\")\n",
    "        self.fake_pca_B_ = self.generator(self.fake_pca_A, self.options, True, name=\"generatorA2B\")\n",
    "        \n",
    "        #### DISCRIMINATOR NETWORKS\n",
    "        # IAIN: create two discriminators networks\n",
    "        # IAIN: discriminate, takes fake_B as input from generator and outputs DB_fake (0-1) 0 = fake, 1 = not_fake\n",
    "        # IAIN: discriminate, takes fake_A as input from generator and outputs DA_fake (0-1) 0 = fake, 1 = not_fake\n",
    "        self.DB_pca_fake = self.discriminator(self.fake_pca_B, self.options, reuse=False, name=\"discriminatorB\")\n",
    "        self.DA_pca_fake = self.discriminator(self.fake_pca_A, self.options, reuse=False, name=\"discriminatorA\")\n",
    "\n",
    "        #### GENERATOR LOSS FUNCTION\n",
    "        # IAIN: definine total loss functions for generator\n",
    "        # IAIN: three loss functions definied\n",
    "        # IAIN: g_loss_a2b and g_loss_b2a are minimised as g_loss is minismised. although they do not impact the network\n",
    "        # in any way, they are recorded so they can be observed independantly in the tf.summary\n",
    "        # IAIN: g_loss is used to optimise the generator network and is made up of four components\n",
    "        # IAIN: adversarial loss: self.criterionGAN(self.DA_pca_fake, tf.ones_like(self.DA_pca_fake))\n",
    "        # IAIN: adversarial loss: self.criterionGAN(self.DB_pca_fake, tf.ones_like(self.DB_pca_fake))\n",
    "        # IAIN: cycle consistancy loss: self.L1_lambda * abs_criterion(self.real_pca_A, self.fake_pca_A_)\n",
    "        # IAIN: cycle consistancy loss: self.L1_lambda * abs_criterion(self.real_pca_B, self.fake_pca_B_)\n",
    "        # IAIN: characteristic loss: self.char_loss_a2b\n",
    "        # IAIN: characteristic loss: self.char_loss_b2a\n",
    "        self.g_loss_a2b = self.criterionGAN(self.DB_pca_fake, tf.ones_like(self.DB_pca_fake)) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_pca_A, self.fake_pca_A_) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_pca_B, self.fake_pca_B_)\n",
    "        self.g_loss_b2a = self.criterionGAN(self.DA_pca_fake, tf.ones_like(self.DA_pca_fake)) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_pca_A, self.fake_pca_A_) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_pca_B, self.fake_pca_B_)\n",
    "        \n",
    "        self.char_loss_a2b = self.L2_lambda * cosine_difference(self.real_pca_A, self.real_pca_mean_A, \n",
    "                                                                self.fake_pca_B, self.real_pca_mean_B)\n",
    "        self.char_loss_b2a = self.L2_lambda * cosine_difference(self.real_pca_B, self.real_pca_mean_B, \n",
    "                                                                self.fake_pca_A, self.real_pca_mean_A)\n",
    "        \n",
    "        \n",
    "        self.g_loss = self.criterionGAN(self.DA_pca_fake, tf.ones_like(self.DA_pca_fake)) \\\n",
    "            + self.criterionGAN(self.DB_pca_fake, tf.ones_like(self.DB_pca_fake)) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_pca_A, self.fake_pca_A_) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_pca_B, self.fake_pca_B_) \\\n",
    "            + self.L2_lambda * cosine_difference(self.real_pca_A, self.real_pca_mean_A, \n",
    "                                                                self.fake_pca_B, self.real_pca_mean_B) \\\n",
    "            + self.L2_lambda * cosine_difference(self.real_pca_B, self.real_pca_mean_B, \n",
    "                                                                self.fake_pca_A, self.real_pca_mean_A)\n",
    "        \n",
    "        \n",
    "        #### INPUTS FOR DISCRIMINATOR NETOWRK\n",
    "        # IAIN: tf.plaeholders for fake_image data created by generator networks\n",
    "        # IAIN: in train function of class you can see fake_A_sample/fake_B_sample \n",
    "        # defined as output of generator network\n",
    "        ##### NOTE!!!!!!! check vs dimension in original construction encase of error included extra dimension info\n",
    "        self.fake_pca_A_sample = tf.placeholder(tf.float32,\n",
    "                                            [None, self.num_components], name='fake_A_sample')\n",
    "        self.fake_pca_B_sample = tf.placeholder(tf.float32,\n",
    "                                            [None, self.num_components], name='fake_B_sample')\n",
    "        \n",
    "        #### DISCRIMINATOR NETWORKS CONTINUED\n",
    "        # IAIN: define 4 outputs from the two discriminator networks\n",
    "        # IAIN: all four outputs fed to discriminator loss function\n",
    "        # IAIN: discriminate, takes real_B as input (raw data) and outputs DB_real (0-1) 0 = ???, 1 = ???\n",
    "        # IAIN: discriminate, takes real_A as input (raw data) and outputs DA_real (0-1) 0 = ???, 1 = ???\n",
    "        # IAIN: discriminate, takes fake_B_sample as input (raw data) and outputs DB_fake_sample (0-1) 0 = ???, 1 = ???\n",
    "        # IAIN: discriminate, takes fake_A_sample as input (raw data) and outputs DA_fake_sample (0-1) 0 = ???, 1 = ???\n",
    "        # IAIN: reuse = TRUE, essentially this reuses the variables from previous discriminator network with the same name i.e. //\n",
    "        # IAIN: // the same discriminator network. The outputs can then be used within the objective functions to optimise that disctiminator. \n",
    "        self.DB_pca_real = self.discriminator(self.real_pca_B, self.options, reuse=True, name=\"discriminatorB\")\n",
    "        self.DA_pca_real = self.discriminator(self.real_pca_A, self.options, reuse=True, name=\"discriminatorA\")\n",
    "        self.DB_pca_fake_sample = self.discriminator(self.fake_pca_B_sample, self.options, reuse=True, name=\"discriminatorB\")\n",
    "        self.DA_pca_fake_sample = self.discriminator(self.fake_pca_A_sample, self.options, reuse=True, name=\"discriminatorA\")\n",
    "        \n",
    "        #### DISCRIMINATOR NETWORKS\n",
    "        # IAIN: discriminator loss function (all variables below help define d_loss)\n",
    "        # IAIN: advasarial loss only\n",
    "        self.db_loss_real = self.criterionGAN(self.DB_pca_real, tf.ones_like(self.DB_pca_real))\n",
    "        self.db_loss_fake = self.criterionGAN(self.DB_pca_fake_sample, tf.zeros_like(self.DB_pca_fake_sample))\n",
    "        self.db_loss = (self.db_loss_real + self.db_loss_fake) / 2\n",
    "        self.da_loss_real = self.criterionGAN(self.DA_pca_real, tf.ones_like(self.DA_pca_real))\n",
    "        self.da_loss_fake = self.criterionGAN(self.DA_pca_fake_sample, tf.zeros_like(self.DA_pca_fake_sample))\n",
    "        self.da_loss = (self.da_loss_real + self.da_loss_fake) / 2\n",
    "        self.d_loss = self.da_loss + self.db_loss\n",
    "\n",
    "        #### CREATE SUMMARY\n",
    "        # tf.summary is a tensorflow module to allow you to track variables over time visually\n",
    "        self.g_loss_a2b_sum = tf.summary.scalar(\"g_loss_a2b\", self.g_loss_a2b)\n",
    "        self.g_loss_b2a_sum = tf.summary.scalar(\"g_loss_b2a\", self.g_loss_b2a)\n",
    "        self.char_loss_a2b_sum = tf.summary.scalar(\"g_char_loss_a2b\", self.char_loss_a2b)\n",
    "        self.char_loss_b2a_sum = tf.summary.scalar(\"g_char_loss_b2a\", self.char_loss_b2a)\n",
    "        self.g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n",
    "        \n",
    "        # tf.summary.merge: https://www.tensorflow.org/api_docs/python/tf/summary/merge\n",
    "        # is a 'protocol buffer' serializing structured data – think XML but smaller, faster, and simpler\n",
    "        self.g_sum = tf.summary.merge([self.g_loss_a2b_sum, self.g_loss_b2a_sum, self.char_loss_a2b_sum,\n",
    "                                       self.char_loss_b2a_sum, self.g_loss_sum])\n",
    "\n",
    "        # tf.summary is a tensorflow module to allow you to track variables over time visually\n",
    "        self.db_loss_sum = tf.summary.scalar(\"db_loss\", self.db_loss)\n",
    "        self.da_loss_sum = tf.summary.scalar(\"da_loss\", self.da_loss)\n",
    "        self.d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n",
    "        self.db_loss_real_sum = tf.summary.scalar(\"db_loss_real\", self.db_loss_real)\n",
    "        self.db_loss_fake_sum = tf.summary.scalar(\"db_loss_fake\", self.db_loss_fake)\n",
    "        self.da_loss_real_sum = tf.summary.scalar(\"da_loss_real\", self.da_loss_real)\n",
    "        self.da_loss_fake_sum = tf.summary.scalar(\"da_loss_fake\", self.da_loss_fake)\n",
    "\n",
    "        # tf.summary.merge: https://www.tensorflow.org/api_docs/python/tf/summary/merge\n",
    "        # is a 'protocol buffer' serializing structured data – think XML but smaller, faster, and simpler\n",
    "        self.d_sum = tf.summary.merge(\n",
    "            [self.da_loss_sum, self.da_loss_real_sum, self.da_loss_fake_sum,\n",
    "             self.db_loss_sum, self.db_loss_real_sum, self.db_loss_fake_sum,\n",
    "             self.d_loss_sum])\n",
    "\n",
    "        \n",
    "        #### TESTING\n",
    "        # IAIN: defines placeholders for test input data\n",
    "        # IAIN: defines testB and testA as output of generator functions for testing\n",
    "        self.test_A = tf.placeholder(tf.float32,\n",
    "                                     [None, self.num_components], name='test_A')\n",
    "        self.test_B = tf.placeholder(tf.float32,\n",
    "                                     [None, self.num_components], name='test_B')\n",
    "        self.testB = self.generator(self.test_A, self.options, True, name=\"generatorA2B\")\n",
    "        self.testA = self.generator(self.test_B, self.options, True, name=\"generatorB2A\")\n",
    "\n",
    "        t_vars = tf.trainable_variables()\n",
    "\n",
    "        \n",
    "        #### TRAINING\n",
    "        # IAIN: d_vars and g_vars used in train function\n",
    "        # IAIN: variables needed for AdamOptimizer\n",
    "        # IAIN: used in AdamOptimizer in conjunction with d_loss and g_loss\n",
    "        self.d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
    "        self.g_vars = [var for var in t_vars if 'generator' in var.name]\n",
    "        for var in t_vars: print(var.name)\n",
    "\n",
    "\n",
    "    def train(self, args):\n",
    "        \"\"\"Train cyclegan\"\"\"\n",
    "        # placeholder for learning rate\n",
    "        self.lr = tf.placeholder(tf.float32, None, name='learning_rate')\n",
    "\n",
    "        # define optimizers for d_loss and g_loss\n",
    "        self.d_optim = tf.train.AdamOptimizer(self.lr, beta1=args.beta1) \\\n",
    "            .minimize(self.d_loss, var_list=self.d_vars)\n",
    "        self.g_optim = tf.train.AdamOptimizer(self.lr, beta1=args.beta1) \\\n",
    "            .minimize(self.g_loss, var_list=self.g_vars)\n",
    "\n",
    "        # initialise global varibles and run session\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        self.sess.run(init_op)\n",
    "\n",
    "        # log writer\n",
    "        self.writer = tf.summary.FileWriter(\"./logs\", self.sess.graph)\n",
    "\n",
    "        # track progress\n",
    "        counter = 1\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train from checkpoint rather than form scratch\n",
    "        if args.continue_train:\n",
    "            if self.load(args.checkpoint_dir):\n",
    "                print(\" [*] Load SUCCESS\")\n",
    "            else:\n",
    "                print(\" [!] Load failed...\")\n",
    "                \n",
    "        #\n",
    "        np_A_pca = self.df_pca_A_train.copy().to_numpy()\n",
    "        np_B_pca = self.df_pca_B_train.copy().to_numpy()\n",
    "        np_A_pca_mean = np_A_pca.mean(axis=0).reshape(1,-1)\n",
    "        np_B_pca_mean = np_B_pca.mean(axis=0).reshape(1,-1)\n",
    "\n",
    "        # iterate over the number of epochs definied\n",
    "        for epoch in range(args.epoch):\n",
    "\n",
    "            # IAIN: create stochastic / batch ???\n",
    "            \n",
    "            ### IMOPRT DATA\n",
    "            # import data\n",
    "            df_A_pca = self.df_pca_A_train.copy()\n",
    "            df_B_pca = self.df_pca_B_train.copy()\n",
    "\n",
    "            # \n",
    "            file_names_A = list(df_A_pca.index)\n",
    "            file_names_B = list(df_B_pca.index)\n",
    "            \n",
    "            # shuffle order of list\n",
    "            np.random.shuffle(file_names_A)\n",
    "            np.random.shuffle(file_names_B)\n",
    "            \n",
    "            ##################################\n",
    "                        \n",
    "            # train size very large, batch size = 1, so this is just min of len(dataA) and len(dataB)\n",
    "            batch_idxs = min(min(len(file_names_A), len(file_names_B)), args.train_size) // self.batch_size\n",
    "            \n",
    "            # the learning rate is kept equal for first 100 epochs and then linearly decays over the next 100\n",
    "            lr = args.lr if epoch < args.epoch_step else args.lr*(args.epoch-epoch)/(args.epoch-args.epoch_step)            \n",
    "            \n",
    "            \n",
    "            ##################################\n",
    "            #  \n",
    "            for idx in range(0, batch_idxs):\n",
    "                \n",
    "                # load one image from each dataset\n",
    "                data_pca_A = df_A_pca.loc[file_names_A[idx * self.batch_size:(idx + 1) * self.batch_size]].to_numpy().astype(np.float32)\n",
    "                data_pca_B = df_B_pca.loc[file_names_B[idx * self.batch_size:(idx + 1) * self.batch_size]].to_numpy().astype(np.float32)\n",
    "                \n",
    "                \n",
    "                ##################################\n",
    "                \n",
    "                \n",
    "                # cast images astype float32\n",
    "                # batch_images = np.array(batch_images).astype(np.float32)\n",
    "\n",
    "                # Update G network and record fake outputs\n",
    "                # input: real images A and B and learning rate\n",
    "                # output: fake images from generator networks and cost / summaries\n",
    "                fake_pca_A, fake_pca_B, _, summary_str = self.sess.run(\n",
    "                    [self.fake_pca_A, self.fake_pca_B, self.g_optim, self.g_sum],\n",
    "                    feed_dict={self.real_pca_A: data_pca_A, \n",
    "                               self.real_pca_B: data_pca_B,\n",
    "                               self.real_pca_mean_A: np_A_pca_mean, \n",
    "                               self.real_pca_mean_B: np_B_pca_mean,\n",
    "                               self.lr: lr})\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "                #[fake_A, fake_B] = self.pool([fake_A, fake_B])\n",
    "                \n",
    "\n",
    "\n",
    "                # Update D network\n",
    "                # input: real / fake images and learning rates\n",
    "                # output: cost / summaries\n",
    "                _, summary_str = self.sess.run(\n",
    "                    [self.d_optim, self.d_sum],\n",
    "                    feed_dict={self.real_pca_A: data_pca_A,\n",
    "                               self.real_pca_B: data_pca_A,\n",
    "                               self.fake_pca_A_sample: fake_pca_A,\n",
    "                               self.fake_pca_B_sample: fake_pca_B,\n",
    "                               self.lr: lr})\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "                \n",
    "                # track progress: print epoch, idx, batch_idxs and runtime\n",
    "                counter += 1\n",
    "                if counter % 5000 == 0:\n",
    "                    print((\"Epoch: [%2d] [%4d/%4d] time: %4.4f\" % (\n",
    "                        epoch, idx, batch_idxs, time.time() - start_time)))\n",
    "\n",
    "                # IAIN: calls class method sample_model\n",
    "                # IAIN: ??? periodically save (and record??) sample model\n",
    "                if epoch in [0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190] and counter == 5000:\n",
    "                    self.sample_model(args.sample_dir, epoch, idx)\n",
    "                \n",
    "\n",
    "                # calls class method save\n",
    "                # IAIN: ???? periodically save sample model\n",
    "                if np.mod(counter, args.save_freq) == 2:\n",
    "                    self.save(args.checkpoint_dir, counter)\n",
    "                    \n",
    "  \n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        # save model\n",
    "        model_name = \"cariGeoGAN.model\"\n",
    "        model_dir = \"%s_%s\" % (self.dataset_dir, self.num_components)\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,\n",
    "                        os.path.join(checkpoint_dir, model_name),\n",
    "                        global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        #load model\n",
    "        print(\" [*] Reading checkpoint...\")\n",
    "\n",
    "        model_dir = \"%s_%s\" % (self.dataset_dir, self.num_components)\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def sample_model(self, sample_dir, epoch, idx):\n",
    "        \n",
    "        ### gather batch of test images\n",
    "        df_A_pca = self.df_pca_A_test.copy()\n",
    "        df_B_pca = self.df_pca_B_test.copy()\n",
    "        \n",
    "        # ...\n",
    "        file_names_A = list(df_A_pca.index)\n",
    "        file_names_B = list(df_B_pca.index)\n",
    "        \n",
    "        \n",
    "        # shuffle order of list\n",
    "        np.random.shuffle(file_names_A)\n",
    "        np.random.shuffle(file_names_B)\n",
    "\n",
    "        # file\n",
    "        files_A = np.random.choice(file_names_A, self.batch_size)\n",
    "        files_B = np.random.choice(file_names_B, self.batch_size)\n",
    "        \n",
    "        # \n",
    "        data_A = df_A_pca.loc[files_A].to_numpy().astype(np.float32)\n",
    "        data_B = df_B_pca.loc[files_B].to_numpy().astype(np.float32)             \n",
    "        \n",
    "        ### feed test images into network and return fake output images\n",
    "        fake_pca_A, fake_pca_B = self.sess.run(\n",
    "            [self.fake_pca_A, self.fake_pca_B],\n",
    "            feed_dict={self.real_pca_A: data_A,\n",
    "                       self.real_pca_B: data_B}\n",
    "        )\n",
    "        \n",
    "        ### reverse pca / reverse scaling\n",
    "        fake_A_recon = self.sc_A.inverse_transform(self.pca_A.inverse_transform(fake_pca_A))\n",
    "        fake_B_recon = self.sc_B.inverse_transform(self.pca_B.inverse_transform(fake_pca_B))\n",
    "        \n",
    "        ### from and to coordintes\n",
    "        coords_from_A = self.df_A_test.loc[files_A].to_numpy().reshape(20,2)\n",
    "        coords_to_A = fake_B_recon.reshape(20,2)\n",
    "        coords_from_B = self.df_B_test.loc[files_B].to_numpy().reshape(20,2) \n",
    "        coords_to_B = fake_A_recon.reshape(20,2)\n",
    "        \n",
    "        # cocatenate boundary points  \n",
    "        coords_from_A = add_boundary_coords(coords_from_A)\n",
    "        coords_to_A = add_boundary_coords(coords_to_A)\n",
    "        coords_from_B = add_boundary_coords(coords_from_B)\n",
    "        coords_to_B = add_boundary_coords(coords_to_B)\n",
    "\n",
    "        \n",
    "        ### original imges\n",
    "        image_A = imread('datasets/faces2cari/images_A/' + files_A[0], is_grayscale = False)\n",
    "        image_B = imread('datasets/faces2cari/images_B/' + files_B[0], is_grayscale = False)\n",
    "        \n",
    "        \n",
    "        ### load and warp image\n",
    "        fake_image_A = warpRBF(image_A, coords_from_A, coords_to_A)\n",
    "        fake_image_B = warpRBF(image_B, coords_from_B, coords_to_B)\n",
    "        \n",
    "        \n",
    "        # summary_image\n",
    "        summary_image_A = cv2.hconcat([image_A, fake_image_A])\n",
    "        summary_image_B = cv2.hconcat([image_B, fake_image_B])\n",
    "        \n",
    "        #\n",
    "        cv2.imwrite('sample/' + files_A[0], summary_image_A)\n",
    "        cv2.imwrite('sample/' + files_B[0], summary_image_B)\n",
    "\n",
    "    def test(self, args):\n",
    "        \"\"\"Test cyclegan\"\"\"\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        self.sess.run(init_op)\n",
    "        \n",
    "        # choose direction for text\n",
    "        if args.which_direction == 'AtoB':\n",
    "            df_test = self.df_A_test.copy()\n",
    "            df_test_pca = self.df_pca_A_test.copy()\n",
    "            sample_files = list(self.df_pca_A_test.index)\n",
    "            directory = 'datasets/faces2cari/images_A/'\n",
    "        elif args.which_direction == 'BtoA':\n",
    "            df_test = self.df_B_test.copy()\n",
    "            df_test_pca = self.df_pca_B_test.copy()\n",
    "            sample_files = list(self.df_pca_B_test.index)\n",
    "            directory = 'datasets/faces2cari/images_B/'\n",
    "        else:\n",
    "            raise Exception('--which_direction must be AtoB or BtoA')\n",
    "        \n",
    "        # load checkpoint\n",
    "        if self.load(args.checkpoint_dir):\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "        else:\n",
    "            print(\" [!] Load failed...\")\n",
    "\n",
    "        # write html for visual comparison\n",
    "        index_path = os.path.join(args.test_dir, '{0}_index.html'.format(args.which_direction))\n",
    "        index = open(index_path, \"w\")\n",
    "        index.write(\"<html><body><table><tr>\")\n",
    "        index.write(\"<th>name</th><th>input</th><th>output</th></tr>\")\n",
    "        \n",
    "        \n",
    "        # direction testing\n",
    "        out_var, in_var, out_pca, out_sc = (self.testB, self.test_A, self.pca_B, self.sc_B) if args.which_direction == 'AtoB' else (\n",
    "            self.testA, self.test_B, self.pca_A, self.sc_A)\n",
    "\n",
    "        \n",
    "        for sample_file in sample_files:\n",
    "\n",
    "            image = imread(directory + sample_file, is_grayscale = False)\n",
    "        \n",
    "            data = df_test_pca.loc[sample_file].to_numpy().astype(np.float32).reshape(1,-1)\n",
    "        \n",
    "            ### feed test images into network and return fake output images\n",
    "            fake_pca = self.sess.run(out_var, feed_dict={in_var: data})\n",
    "\n",
    "            ### reverse pca / reverse scaling\n",
    "            fake_recon = out_sc.inverse_transform(out_pca.inverse_transform(fake_pca))\n",
    "\n",
    "            ### from and to coordintes\n",
    "            coords_from = df_test.loc[sample_file].to_numpy().reshape(20,2)\n",
    "            coords_to = fake_recon.reshape(20,2)\n",
    "\n",
    "            # cocatenate boundary points  \n",
    "            coords_from = add_boundary_coords(coords_from)\n",
    "            coords_to = add_boundary_coords(coords_to)\n",
    "\n",
    "\n",
    "            ### load and warp image\n",
    "            fake_image = warpRBF(image, coords_from, coords_to)\n",
    "            \n",
    "            # summary_image\n",
    "            summary_image = cv2.hconcat([image, fake_image])\n",
    "       \n",
    "\n",
    "            ### save images in sample model directory\n",
    "            cv2.imwrite('test/' + sample_file, summary_image)\n",
    "            \n",
    "    def new(self, args, image, coords):\n",
    "        \"\"\"Test cyclegan\"\"\"\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        self.sess.run(init_op)\n",
    "                \n",
    "        # load checkpoint\n",
    "        if self.load(args.checkpoint_dir):\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "        else:\n",
    "            print(\" [!] Load failed...\") \n",
    "            \n",
    "        \n",
    "        # coords_pca\n",
    "        coords_pca = self.pca_A.transform(self.sc_A.transform(coords))\n",
    "        \n",
    "        \n",
    "        # direction testing\n",
    "        out_var, in_var, out_pca, out_sc = (self.testB, self.test_A, self.pca_B, self.sc_B) if args.which_direction == 'AtoB' else (\n",
    "            self.testA, self.test_B, self.pca_A, self.sc_A)\n",
    "\n",
    "        ### feed test images into network and return fake output images\n",
    "        fake_pca = self.sess.run(out_var, feed_dict={in_var: coords_pca})\n",
    "\n",
    "        ### reverse pca / reverse scaling\n",
    "        fake_recon = out_sc.inverse_transform(out_pca.inverse_transform(fake_pca))\n",
    "\n",
    "        ### from and to coordintes\n",
    "        coords_from = coords.reshape(20,2)\n",
    "        coords_to = fake_recon.reshape(20,2)\n",
    "\n",
    "        # cocatenate boundary points  \n",
    "        coords_from = add_boundary_coords(coords_from)\n",
    "        coords_to = add_boundary_coords(coords_to)\n",
    "\n",
    "\n",
    "        ### load and warp image\n",
    "        fake_image = warpRBF(image, coords_from, coords_to)\n",
    "\n",
    "        # summary_image\n",
    "        summary_image = cv2.hconcat([image, fake_image])\n",
    "\n",
    "\n",
    "        ### save images in sample model directory\n",
    "        cv2.imwrite('new/' + 'new_cari.jpg', summary_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    dataset_dir = 'faces2cari'\n",
    "    epoch = 200\n",
    "    epoch_step = 100\n",
    "    batch_size = 1\n",
    "    train_size = 1e8\n",
    "    load_size = 286\n",
    "    pca_components = 32\n",
    "    ngf = 64\n",
    "    ndf = 64\n",
    "    lr = 0.0002\n",
    "    beta1 = 0.5\n",
    "    which_direction = 'AtoB'\n",
    "    phase = 'test'\n",
    "    save_freq = 5000\n",
    "    print_freq = 100\n",
    "    continue_train = False\n",
    "    checkpoint_dir = './checkpoint'\n",
    "    sample_dir = './sample'\n",
    "    test_dir = './test'\n",
    "    L1_lambda = 10.0\n",
    "    L2_lambda = 1.0\n",
    "    use_lsgan = True\n",
    "    max_size = 50\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generatorA2B/W_g_e1:0\n",
      "generatorA2B/b_g_e1:0\n",
      "generatorA2B/W_g_e2:0\n",
      "generatorA2B/b_g_e2:0\n",
      "generatorA2B/W_g_e3:0\n",
      "generatorA2B/b_g_e3:0\n",
      "generatorA2B/W_g_e4:0\n",
      "generatorA2B/b_g_e4:0\n",
      "generatorA2B/W_g_e5:0\n",
      "generatorA2B/b_g_e5:0\n",
      "generatorA2B/W_g_e6:0\n",
      "generatorA2B/b_g_e6:0\n",
      "generatorA2B/W_g_e7:0\n",
      "generatorA2B/b_g_e7:0\n",
      "generatorA2B/W_g_e8:0\n",
      "generatorA2B/b_g_e8:0\n",
      "generatorB2A/W_g_e1:0\n",
      "generatorB2A/b_g_e1:0\n",
      "generatorB2A/W_g_e2:0\n",
      "generatorB2A/b_g_e2:0\n",
      "generatorB2A/W_g_e3:0\n",
      "generatorB2A/b_g_e3:0\n",
      "generatorB2A/W_g_e4:0\n",
      "generatorB2A/b_g_e4:0\n",
      "generatorB2A/W_g_e5:0\n",
      "generatorB2A/b_g_e5:0\n",
      "generatorB2A/W_g_e6:0\n",
      "generatorB2A/b_g_e6:0\n",
      "generatorB2A/W_g_e7:0\n",
      "generatorB2A/b_g_e7:0\n",
      "generatorB2A/W_g_e8:0\n",
      "generatorB2A/b_g_e8:0\n",
      "discriminatorB/W_d_h0:0\n",
      "discriminatorB/b_d_h0:0\n",
      "discriminatorB/W_d_h1:0\n",
      "discriminatorB/b_d_h1:0\n",
      "discriminatorB/W_d_h2:0\n",
      "discriminatorB/b_d_h2:0\n",
      "discriminatorB/W_d_h3:0\n",
      "discriminatorB/b_d_h3:0\n",
      "discriminatorB/W_d_h4:0\n",
      "discriminatorB/b_d_h4:0\n",
      "discriminatorA/W_d_h0:0\n",
      "discriminatorA/b_d_h0:0\n",
      "discriminatorA/W_d_h1:0\n",
      "discriminatorA/b_d_h1:0\n",
      "discriminatorA/W_d_h2:0\n",
      "discriminatorA/b_d_h2:0\n",
      "discriminatorA/W_d_h3:0\n",
      "discriminatorA/b_d_h3:0\n",
      "discriminatorA/W_d_h4:0\n",
      "discriminatorA/b_d_h4:0\n",
      "Epoch: [ 0] [4998/5874] time: 47.9457\n",
      "Epoch: [ 1] [4124/5874] time: 94.8279\n",
      "Epoch: [ 2] [3250/5874] time: 141.7142\n",
      "Epoch: [ 3] [2376/5874] time: 187.8882\n",
      "Epoch: [ 4] [1502/5874] time: 233.9261\n",
      "Epoch: [ 5] [ 628/5874] time: 281.5467\n",
      "Epoch: [ 5] [5628/5874] time: 333.5661\n",
      "Epoch: [ 6] [4754/5874] time: 379.0468\n",
      "Epoch: [ 7] [3880/5874] time: 427.0745\n",
      "Epoch: [ 8] [3006/5874] time: 476.1335\n",
      "Epoch: [ 9] [2132/5874] time: 522.4650\n",
      "Epoch: [10] [1258/5874] time: 568.3404\n",
      "Epoch: [11] [ 384/5874] time: 614.5518\n",
      "Epoch: [11] [5384/5874] time: 661.0188\n",
      "Epoch: [12] [4510/5874] time: 707.1793\n",
      "Epoch: [13] [3636/5874] time: 753.5366\n",
      "Epoch: [14] [2762/5874] time: 798.9715\n",
      "Epoch: [15] [1888/5874] time: 844.9056\n",
      "Epoch: [16] [1014/5874] time: 890.9415\n",
      "Epoch: [17] [ 140/5874] time: 936.7515\n",
      "Epoch: [17] [5140/5874] time: 983.6636\n",
      "Epoch: [18] [4266/5874] time: 1031.0707\n",
      "Epoch: [19] [3392/5874] time: 1079.4917\n",
      "Epoch: [20] [2518/5874] time: 1127.6758\n",
      "Epoch: [21] [1644/5874] time: 1175.6575\n",
      "Epoch: [22] [ 770/5874] time: 1223.5793\n",
      "Epoch: [22] [5770/5874] time: 1273.2365\n",
      "Epoch: [23] [4896/5874] time: 1322.0945\n",
      "Epoch: [24] [4022/5874] time: 1370.3663\n",
      "Epoch: [25] [3148/5874] time: 1418.8598\n",
      "Epoch: [26] [2274/5874] time: 1466.7860\n",
      "Epoch: [27] [1400/5874] time: 1514.4109\n",
      "Epoch: [28] [ 526/5874] time: 1562.7167\n",
      "Epoch: [28] [5526/5874] time: 1612.3252\n",
      "Epoch: [29] [4652/5874] time: 1660.0747\n",
      "Epoch: [30] [3778/5874] time: 1708.3989\n",
      "Epoch: [31] [2904/5874] time: 1756.8031\n",
      "Epoch: [32] [2030/5874] time: 1805.9447\n",
      "Epoch: [33] [1156/5874] time: 1854.0560\n",
      "Epoch: [34] [ 282/5874] time: 1902.2803\n",
      "Epoch: [34] [5282/5874] time: 1951.3633\n",
      "Epoch: [35] [4408/5874] time: 1999.4138\n",
      "Epoch: [36] [3534/5874] time: 2047.8366\n",
      "Epoch: [37] [2660/5874] time: 2095.4454\n",
      "Epoch: [38] [1786/5874] time: 2145.1353\n",
      "Epoch: [39] [ 912/5874] time: 2193.2812\n",
      "Epoch: [40] [  38/5874] time: 2243.1721\n",
      "Epoch: [40] [5038/5874] time: 2292.7438\n",
      "Epoch: [41] [4164/5874] time: 2340.4641\n",
      "Epoch: [42] [3290/5874] time: 2388.7408\n",
      "Epoch: [43] [2416/5874] time: 2436.7612\n",
      "Epoch: [44] [1542/5874] time: 2484.8603\n",
      "Epoch: [45] [ 668/5874] time: 2533.0305\n",
      "Epoch: [45] [5668/5874] time: 2581.5950\n",
      "Epoch: [46] [4794/5874] time: 2629.6065\n",
      "Epoch: [47] [3920/5874] time: 2677.2971\n",
      "Epoch: [48] [3046/5874] time: 2725.8026\n",
      "Epoch: [49] [2172/5874] time: 2774.8745\n",
      "Epoch: [50] [1298/5874] time: 2822.7659\n",
      "Epoch: [51] [ 424/5874] time: 2871.7659\n",
      "Epoch: [51] [5424/5874] time: 2918.8942\n",
      "Epoch: [52] [4550/5874] time: 2966.1248\n",
      "Epoch: [53] [3676/5874] time: 3013.6418\n",
      "Epoch: [54] [2802/5874] time: 3061.8877\n",
      "Epoch: [55] [1928/5874] time: 3108.8709\n",
      "Epoch: [56] [1054/5874] time: 3156.5788\n",
      "Epoch: [57] [ 180/5874] time: 3204.4514\n",
      "Epoch: [57] [5180/5874] time: 3252.1925\n",
      "Epoch: [58] [4306/5874] time: 3298.9175\n",
      "Epoch: [59] [3432/5874] time: 3346.8962\n",
      "Epoch: [60] [2558/5874] time: 3393.8287\n",
      "Epoch: [61] [1684/5874] time: 3441.3125\n",
      "Epoch: [62] [ 810/5874] time: 3488.0559\n",
      "Epoch: [62] [5810/5874] time: 3535.6445\n",
      "Epoch: [63] [4936/5874] time: 3582.8878\n",
      "Epoch: [64] [4062/5874] time: 3630.0552\n",
      "Epoch: [65] [3188/5874] time: 3676.0810\n",
      "Epoch: [66] [2314/5874] time: 3722.6938\n",
      "Epoch: [67] [1440/5874] time: 3769.2786\n",
      "Epoch: [68] [ 566/5874] time: 3815.9149\n",
      "Epoch: [68] [5566/5874] time: 3861.9933\n",
      "Epoch: [69] [4692/5874] time: 3908.8809\n",
      "Epoch: [70] [3818/5874] time: 3955.6312\n",
      "Epoch: [71] [2944/5874] time: 4003.3074\n",
      "Epoch: [72] [2070/5874] time: 4050.1215\n",
      "Epoch: [73] [1196/5874] time: 4096.6675\n",
      "Epoch: [74] [ 322/5874] time: 4144.0205\n",
      "Epoch: [74] [5322/5874] time: 4190.9779\n",
      "Epoch: [75] [4448/5874] time: 4237.9370\n",
      "Epoch: [76] [3574/5874] time: 4285.1130\n",
      "Epoch: [77] [2700/5874] time: 4331.4323\n",
      "Epoch: [78] [1826/5874] time: 4379.0733\n",
      "Epoch: [79] [ 952/5874] time: 4426.6371\n",
      "Epoch: [80] [  78/5874] time: 4473.0092\n",
      "Epoch: [80] [5078/5874] time: 4519.0223\n",
      "Epoch: [81] [4204/5874] time: 4566.2933\n",
      "Epoch: [82] [3330/5874] time: 4612.8062\n",
      "Epoch: [83] [2456/5874] time: 4659.6952\n",
      "Epoch: [84] [1582/5874] time: 4705.5280\n",
      "Epoch: [85] [ 708/5874] time: 4751.9859\n",
      "Epoch: [85] [5708/5874] time: 4798.4030\n",
      "Epoch: [86] [4834/5874] time: 4846.1585\n",
      "Epoch: [87] [3960/5874] time: 4893.2198\n",
      "Epoch: [88] [3086/5874] time: 4939.3473\n",
      "Epoch: [89] [2212/5874] time: 4986.5139\n",
      "Epoch: [90] [1338/5874] time: 5044.0272\n",
      "Epoch: [91] [ 464/5874] time: 5097.5458\n",
      "Epoch: [91] [5464/5874] time: 5160.1176\n",
      "Epoch: [92] [4590/5874] time: 5224.9820\n",
      "Epoch: [93] [3716/5874] time: 5286.7740\n",
      "Epoch: [94] [2842/5874] time: 5336.8935\n",
      "Epoch: [95] [1968/5874] time: 5392.3402\n",
      "Epoch: [96] [1094/5874] time: 5447.0183\n",
      "Epoch: [97] [ 220/5874] time: 5497.7978\n",
      "Epoch: [97] [5220/5874] time: 5545.8604\n",
      "Epoch: [98] [4346/5874] time: 5599.3390\n",
      "Epoch: [99] [3472/5874] time: 5655.2158\n",
      "Epoch: [100] [2598/5874] time: 5704.1908\n",
      "Epoch: [101] [1724/5874] time: 5771.2267\n",
      "Epoch: [102] [ 850/5874] time: 5848.4609\n",
      "Epoch: [102] [5850/5874] time: 5914.8233\n",
      "Epoch: [103] [4976/5874] time: 5979.3391\n",
      "Epoch: [104] [4102/5874] time: 6051.4942\n",
      "Epoch: [105] [3228/5874] time: 6109.2838\n",
      "Epoch: [106] [2354/5874] time: 6161.6335\n",
      "Epoch: [107] [1480/5874] time: 6212.5354\n",
      "Epoch: [108] [ 606/5874] time: 6272.3826\n",
      "Epoch: [108] [5606/5874] time: 6336.8585\n",
      "Epoch: [109] [4732/5874] time: 6399.5739\n",
      "Epoch: [110] [3858/5874] time: 6476.0011\n",
      "Epoch: [111] [2984/5874] time: 6547.2269\n",
      "Epoch: [112] [2110/5874] time: 6632.1264\n",
      "Epoch: [113] [1236/5874] time: 6700.9333\n",
      "Epoch: [114] [ 362/5874] time: 6775.7812\n",
      "Epoch: [114] [5362/5874] time: 6826.3757\n",
      "Epoch: [115] [4488/5874] time: 6874.1409\n",
      "Epoch: [116] [3614/5874] time: 6921.6817\n",
      "Epoch: [117] [2740/5874] time: 6974.3274\n",
      "Epoch: [118] [1866/5874] time: 7040.3609\n",
      "Epoch: [119] [ 992/5874] time: 7121.6737\n",
      "Epoch: [120] [ 118/5874] time: 7197.8344\n",
      "Epoch: [120] [5118/5874] time: 7257.6648\n",
      "Epoch: [121] [4244/5874] time: 7304.3030\n",
      "Epoch: [122] [3370/5874] time: 7365.9152\n",
      "Epoch: [123] [2496/5874] time: 7432.0132\n",
      "Epoch: [124] [1622/5874] time: 7487.9065\n",
      "Epoch: [125] [ 748/5874] time: 7544.6441\n",
      "Epoch: [125] [5748/5874] time: 7598.4999\n",
      "Epoch: [126] [4874/5874] time: 7645.5702\n",
      "Epoch: [127] [4000/5874] time: 7692.7508\n",
      "Epoch: [128] [3126/5874] time: 7740.5173\n",
      "Epoch: [129] [2252/5874] time: 7788.6823\n",
      "Epoch: [130] [1378/5874] time: 7843.3223\n",
      "Epoch: [131] [ 504/5874] time: 7891.9102\n",
      "Epoch: [131] [5504/5874] time: 7939.1711\n",
      "Epoch: [132] [4630/5874] time: 7985.9302\n",
      "Epoch: [133] [3756/5874] time: 8032.6019\n",
      "Epoch: [134] [2882/5874] time: 8078.7082\n",
      "Epoch: [135] [2008/5874] time: 8125.3079\n",
      "Epoch: [136] [1134/5874] time: 8171.8813\n",
      "Epoch: [137] [ 260/5874] time: 8217.9489\n",
      "Epoch: [137] [5260/5874] time: 8264.3502\n",
      "Epoch: [138] [4386/5874] time: 8315.8601\n",
      "Epoch: [139] [3512/5874] time: 8365.5458\n",
      "Epoch: [140] [2638/5874] time: 8423.0318\n",
      "Epoch: [141] [1764/5874] time: 8478.6037\n",
      "Epoch: [142] [ 890/5874] time: 8533.8197\n",
      "Epoch: [143] [  16/5874] time: 8589.5136\n",
      "Epoch: [143] [5016/5874] time: 8643.9444\n",
      "Epoch: [144] [4142/5874] time: 8698.5990\n",
      "Epoch: [145] [3268/5874] time: 8753.9297\n",
      "Epoch: [146] [2394/5874] time: 8808.7980\n",
      "Epoch: [147] [1520/5874] time: 8864.9683\n",
      "Epoch: [148] [ 646/5874] time: 8920.3283\n",
      "Epoch: [148] [5646/5874] time: 8974.8797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [149] [4772/5874] time: 9029.6634\n",
      "Epoch: [150] [3898/5874] time: 9084.2228\n",
      "Epoch: [151] [3024/5874] time: 9139.2001\n",
      "Epoch: [152] [2150/5874] time: 9194.7084\n",
      "Epoch: [153] [1276/5874] time: 9248.9081\n",
      "Epoch: [154] [ 402/5874] time: 9303.2621\n",
      "Epoch: [154] [5402/5874] time: 9358.1980\n",
      "Epoch: [155] [4528/5874] time: 9412.7964\n",
      "Epoch: [156] [3654/5874] time: 9469.2563\n",
      "Epoch: [157] [2780/5874] time: 9524.1969\n",
      "Epoch: [158] [1906/5874] time: 9578.7634\n",
      "Epoch: [159] [1032/5874] time: 9633.9845\n",
      "Epoch: [160] [ 158/5874] time: 9689.9565\n",
      "Epoch: [160] [5158/5874] time: 9743.8126\n",
      "Epoch: [161] [4284/5874] time: 9792.6768\n",
      "Epoch: [162] [3410/5874] time: 9842.1262\n",
      "Epoch: [163] [2536/5874] time: 9896.8680\n",
      "Epoch: [164] [1662/5874] time: 9951.9655\n",
      "Epoch: [165] [ 788/5874] time: 10006.6087\n",
      "Epoch: [165] [5788/5874] time: 10061.9642\n",
      "Epoch: [166] [4914/5874] time: 10117.9825\n",
      "Epoch: [167] [4040/5874] time: 10173.3206\n",
      "Epoch: [168] [3166/5874] time: 10229.2104\n",
      "Epoch: [169] [2292/5874] time: 10283.9174\n",
      "Epoch: [170] [1418/5874] time: 10339.5061\n",
      "Epoch: [171] [ 544/5874] time: 10394.2130\n",
      "Epoch: [171] [5544/5874] time: 10448.7634\n",
      "Epoch: [172] [4670/5874] time: 10499.9246\n",
      "Epoch: [173] [3796/5874] time: 10549.2899\n",
      "Epoch: [174] [2922/5874] time: 10598.2069\n",
      "Epoch: [175] [2048/5874] time: 10644.8622\n",
      "Epoch: [176] [1174/5874] time: 10692.9319\n",
      "Epoch: [177] [ 300/5874] time: 10762.8077\n",
      "Epoch: [177] [5300/5874] time: 10809.6986\n",
      "Epoch: [178] [4426/5874] time: 10858.6406\n",
      "Epoch: [179] [3552/5874] time: 10905.5637\n",
      "Epoch: [180] [2678/5874] time: 10956.3214\n",
      "Epoch: [181] [1804/5874] time: 11010.7677\n",
      "Epoch: [182] [ 930/5874] time: 11064.6503\n",
      "Epoch: [183] [  56/5874] time: 11117.5672\n",
      "Epoch: [183] [5056/5874] time: 11165.5915\n",
      "Epoch: [184] [4182/5874] time: 11212.2948\n",
      "Epoch: [185] [3308/5874] time: 11266.3810\n",
      "Epoch: [186] [2434/5874] time: 11316.1673\n",
      "Epoch: [187] [1560/5874] time: 11369.3739\n",
      "Epoch: [188] [ 686/5874] time: 11426.6007\n",
      "Epoch: [188] [5686/5874] time: 11497.6017\n",
      "Epoch: [189] [4812/5874] time: 11570.1929\n",
      "Epoch: [190] [3938/5874] time: 11637.9718\n",
      "Epoch: [191] [3064/5874] time: 11699.7352\n",
      "Epoch: [192] [2190/5874] time: 11769.4015\n",
      "Epoch: [193] [1316/5874] time: 11839.1689\n",
      "Epoch: [194] [ 442/5874] time: 11916.6551\n",
      "Epoch: [194] [5442/5874] time: 11976.6912\n",
      "Epoch: [195] [4568/5874] time: 12031.2070\n",
      "Epoch: [196] [3694/5874] time: 12086.6783\n",
      "Epoch: [197] [2820/5874] time: 12141.1773\n",
      "Epoch: [198] [1946/5874] time: 12194.9431\n",
      "Epoch: [199] [1072/5874] time: 12256.5157\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tfconfig = tf.ConfigProto(allow_soft_placement=True)\n",
    "tfconfig.gpu_options.allow_growth = True\n",
    "with tf.Session(config=tfconfig) as sess:\n",
    "    model = cariGeoGAN(sess, args)\n",
    "    model.train(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESTORE\n",
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generatorA2B/W_g_e1:0\n",
      "generatorA2B/b_g_e1:0\n",
      "generatorA2B/W_g_e2:0\n",
      "generatorA2B/b_g_e2:0\n",
      "generatorA2B/W_g_e3:0\n",
      "generatorA2B/b_g_e3:0\n",
      "generatorA2B/W_g_e4:0\n",
      "generatorA2B/b_g_e4:0\n",
      "generatorA2B/W_g_e5:0\n",
      "generatorA2B/b_g_e5:0\n",
      "generatorA2B/W_g_e6:0\n",
      "generatorA2B/b_g_e6:0\n",
      "generatorA2B/W_g_e7:0\n",
      "generatorA2B/b_g_e7:0\n",
      "generatorA2B/W_g_e8:0\n",
      "generatorA2B/b_g_e8:0\n",
      "generatorB2A/W_g_e1:0\n",
      "generatorB2A/b_g_e1:0\n",
      "generatorB2A/W_g_e2:0\n",
      "generatorB2A/b_g_e2:0\n",
      "generatorB2A/W_g_e3:0\n",
      "generatorB2A/b_g_e3:0\n",
      "generatorB2A/W_g_e4:0\n",
      "generatorB2A/b_g_e4:0\n",
      "generatorB2A/W_g_e5:0\n",
      "generatorB2A/b_g_e5:0\n",
      "generatorB2A/W_g_e6:0\n",
      "generatorB2A/b_g_e6:0\n",
      "generatorB2A/W_g_e7:0\n",
      "generatorB2A/b_g_e7:0\n",
      "generatorB2A/W_g_e8:0\n",
      "generatorB2A/b_g_e8:0\n",
      "discriminatorB/W_d_h0:0\n",
      "discriminatorB/b_d_h0:0\n",
      "discriminatorB/W_d_h1:0\n",
      "discriminatorB/b_d_h1:0\n",
      "discriminatorB/W_d_h2:0\n",
      "discriminatorB/b_d_h2:0\n",
      "discriminatorB/W_d_h3:0\n",
      "discriminatorB/b_d_h3:0\n",
      "discriminatorB/W_d_h4:0\n",
      "discriminatorB/b_d_h4:0\n",
      "discriminatorA/W_d_h0:0\n",
      "discriminatorA/b_d_h0:0\n",
      "discriminatorA/W_d_h1:0\n",
      "discriminatorA/b_d_h1:0\n",
      "discriminatorA/W_d_h2:0\n",
      "discriminatorA/b_d_h2:0\n",
      "discriminatorA/W_d_h3:0\n",
      "discriminatorA/b_d_h3:0\n",
      "discriminatorA/W_d_h4:0\n",
      "discriminatorA/b_d_h4:0\n",
      " [*] Reading checkpoint...\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/faces2cari_32/cariGeoGAN.model-1170002\n",
      " [*] Load SUCCESS\n"
     ]
    }
   ],
   "source": [
    "run_test = True\n",
    "\n",
    "if run_test:\n",
    "    # TEST\n",
    "    tfconfig = tf.ConfigProto(allow_soft_placement=True)\n",
    "    tfconfig.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=tfconfig) as sess:\n",
    "        model_restored = cariGeoGAN(sess, args)\n",
    "        model_restored.test(args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESTORE\n",
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generatorA2B/W_g_e1:0\n",
      "generatorA2B/b_g_e1:0\n",
      "generatorA2B/W_g_e2:0\n",
      "generatorA2B/b_g_e2:0\n",
      "generatorA2B/W_g_e3:0\n",
      "generatorA2B/b_g_e3:0\n",
      "generatorA2B/W_g_e4:0\n",
      "generatorA2B/b_g_e4:0\n",
      "generatorA2B/W_g_e5:0\n",
      "generatorA2B/b_g_e5:0\n",
      "generatorA2B/W_g_e6:0\n",
      "generatorA2B/b_g_e6:0\n",
      "generatorA2B/W_g_e7:0\n",
      "generatorA2B/b_g_e7:0\n",
      "generatorA2B/W_g_e8:0\n",
      "generatorA2B/b_g_e8:0\n",
      "generatorB2A/W_g_e1:0\n",
      "generatorB2A/b_g_e1:0\n",
      "generatorB2A/W_g_e2:0\n",
      "generatorB2A/b_g_e2:0\n",
      "generatorB2A/W_g_e3:0\n",
      "generatorB2A/b_g_e3:0\n",
      "generatorB2A/W_g_e4:0\n",
      "generatorB2A/b_g_e4:0\n",
      "generatorB2A/W_g_e5:0\n",
      "generatorB2A/b_g_e5:0\n",
      "generatorB2A/W_g_e6:0\n",
      "generatorB2A/b_g_e6:0\n",
      "generatorB2A/W_g_e7:0\n",
      "generatorB2A/b_g_e7:0\n",
      "generatorB2A/W_g_e8:0\n",
      "generatorB2A/b_g_e8:0\n",
      "discriminatorB/W_d_h0:0\n",
      "discriminatorB/b_d_h0:0\n",
      "discriminatorB/W_d_h1:0\n",
      "discriminatorB/b_d_h1:0\n",
      "discriminatorB/W_d_h2:0\n",
      "discriminatorB/b_d_h2:0\n",
      "discriminatorB/W_d_h3:0\n",
      "discriminatorB/b_d_h3:0\n",
      "discriminatorB/W_d_h4:0\n",
      "discriminatorB/b_d_h4:0\n",
      "discriminatorA/W_d_h0:0\n",
      "discriminatorA/b_d_h0:0\n",
      "discriminatorA/W_d_h1:0\n",
      "discriminatorA/b_d_h1:0\n",
      "discriminatorA/W_d_h2:0\n",
      "discriminatorA/b_d_h2:0\n",
      "discriminatorA/W_d_h3:0\n",
      "discriminatorA/b_d_h3:0\n",
      "discriminatorA/W_d_h4:0\n",
      "discriminatorA/b_d_h4:0\n",
      " [*] Reading checkpoint...\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/faces2cari_32/cariGeoGAN.model-1170002\n",
      " [*] Load SUCCESS\n"
     ]
    }
   ],
   "source": [
    "run_new = True\n",
    "image = cv2.imread('new/new.jpg')\n",
    "coords_df = pd.read_csv('new/new_coords.csv', index_col=0)\n",
    "coords = coords_df.to_numpy()\n",
    "\n",
    "if run_new:\n",
    "    # TEST\n",
    "    tfconfig = tf.ConfigProto(allow_soft_placement=True)\n",
    "    tfconfig.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=tfconfig) as sess:\n",
    "        model_restored = cariGeoGAN(sess, args)\n",
    "        model_restored.new(args, image, coords)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cariGAN]",
   "language": "python",
   "name": "conda-env-cariGAN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
